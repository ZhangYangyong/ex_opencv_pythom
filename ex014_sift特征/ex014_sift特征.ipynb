{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae55b0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "365b26ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# harris角点检测不具有尺度不变性,SIFT具有尺度不变性,检测出的结果叫局部特征描述子,用一个数组来表述特征"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beee23ea",
   "metadata": {},
   "source": [
    "![img](https://pic3.zhimg.com/v2-2394ea944751ce0d2be178e15798e9ae_r.jpg)\n",
    "\n",
    "\n",
    "缺点：实时性不高、有时特征点较少、对边缘光滑的目标无法准确提取特征点。对模糊的图像和边缘平滑的图像，检测出的特征点过少，对圆更是无能为力。改进后的著名算法有SURF和CSIFT。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26e2dfec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 原理\n",
    "# https://zhuanlan.zhihu.com/p/421792422\n",
    "# https://www.cnblogs.com/wangguchangqing/p/4853263.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "656621f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对原图进行多次下采样实现图像金字塔\n",
    "# 对同一尺寸的图片施加不同σ的高斯滤波,实现不同清晰程度的图片采样\n",
    "# 生成高斯差分金字塔(同一阶金字塔内部多张不同σ的高斯模糊图像,相邻两张之间做减法,求差分) DOG差分金字塔\n",
    "    # 求差分为什么能体现关键点信息,对于不同的像素位置,同一位置两张相减,\n",
    "    # 差值大的地方意味着该位置,图像区别比较大,能体现这这两张图不同之处的特征\n",
    "# DOG 空间极值检测 \n",
    "    # 针对每个点,检测起是否是本张及上下两张不同差分图3*3邻域内(8+9+9 =26)的极值点 \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80614fc9",
   "metadata": {},
   "source": [
    "![image.png](https://pic2.zhimg.com/80/v2-4b7203cfc137b3c5d62257704b2cd271_720w.webp)\n",
    "![image-2.png](https://pic2.zhimg.com/80/v2-4700bdc2d19353dded6e02e5df7b16b1_720w.webp)\n",
    "![image-3.png](https://pic3.zhimg.com/80/v2-5cc18d4d6532b6deb8e2e1ef9cca667e_720w.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ecb2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 经过DOG极值点检测的得到的点是 一些离散的坐标点,相邻两个候选极值点之间(可能)隔了几个像素,\n",
    "                                                    #(其所在位置的差分值不是不是真正的极值)\n",
    "# 所以要通过对离散点进行连续函数的建模得到真正的极值点\n",
    "# 利用二阶泰勒级数 f(x) = f(0)+f'(0)x+ f''(0)x^2/2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a57658fe",
   "metadata": {},
   "source": [
    "![img](https://pic2.zhimg.com/80/v2-8372f329cbd78d1787c3afd341664111_720w.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1503e8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 去除弱响应的特征点\n",
    "# 消除在落在差分图边缘上的极值点(和角点检测一样,用二次型判定是否在差分图图形边缘)\n",
    "# 剩下的特征点就是保留的特征点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f11b34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 对于得到的特征点 此时拥有(xyσ)三个信息\n",
    "# 然后求这个点所在位置邻域(3*1.5σ)范围所有坐标的梯度的大小和方向(在差分图上计算),归类到8个方向上\n",
    "    # 实际梯度直方图将0~360度的方向范围分为36个柱(bins)，其中每柱10度。\n",
    "    \n",
    "# 拥有最多统计数量的方向及拥有最多数量的方向80%以上的第二方向都将作为主方向(复制一份坐标和尺度)\n",
    "#(拥有辅方向的关键点约占全部特征点的15%,但可以明显的提高关键点匹配的稳定性)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52971f44",
   "metadata": {},
   "source": [
    "![img](https://pic1.zhimg.com/80/v2-57088e998772c1a08d746bfa57a8eb7c_720w.webp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd446c7c",
   "metadata": {},
   "source": [
    "![img](https://pic4.zhimg.com/80/v2-c6f55218310e7a30c4075890d1759d63_720w.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4edd9d0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 生成特征的描述\n",
    "# 旋转坐标轴对齐某个特征点的主方向\n",
    "# 特征描述子与特征点所在的尺度有关，因此，对梯度的求取应在特征点对应的高斯图像上进行\n",
    "# 计算关键段周围(旋转后坐标下)16*16窗口内的梯度,16*16又分为16个4*4的种子窗口\n",
    "# 每个种子窗口4*4->16个梯度信息->归类到8个方向->8维向量->16个8维向量->展平->128维向量\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "30f7a787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1098\n",
      "<class 'numpy.ndarray'> (1098, 128)\n"
     ]
    }
   ],
   "source": [
    "# 使用\n",
    "\n",
    "# 创建sift对象\n",
    "sift = cv2.xfeatures2d.SIFT_create() # <3.4.1.15 opencv-contrib-python\n",
    "img = cv2.imread('../data/linna.jpg')\n",
    "\n",
    "# 灰度化\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 检测\n",
    "kp = sift.detect(gray)\n",
    "# print(kp) # 一个列表,里面是关键点对象\n",
    "print(len(kp))\n",
    "\n",
    "# 计算描述子\n",
    "kp,des = sift.compute(gray,kp)\n",
    "print(type(des),des.shape)\n",
    "\n",
    "# 绘制关键点\n",
    "cv2.drawKeypoints(img,kp,img)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# 一步计算描述子和kp\n",
    "kp,des = sift.detectAndCompute(gray,None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fa6da384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 补充\n",
    "# sift surf orb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e0609c8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "surf = cv2.xfeatures2d.SURF_create()\n",
    "img = cv2.imread('../data/linna.jpg')\n",
    "\n",
    "# 灰度化\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "kp,des = surf.detectAndCompute(gray,None)\n",
    "\n",
    "# 绘制关键点\n",
    "cv2.drawKeypoints(img,kp,img)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "760b42c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "orb = cv2.ORB_create()\n",
    "img = cv2.imread('../data/linna.jpg')\n",
    "\n",
    "# 灰度化\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n",
    "kp,des = orb.detectAndCompute(gray,None)\n",
    "\n",
    "# 绘制关键点\n",
    "cv2.drawKeypoints(img,kp,img)\n",
    "\n",
    "cv2.imshow('img',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a41852da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取特征点和描述子后,可以对两幅图像进行特征匹配\n",
    "# BF(Brute-Froce)暴力特征匹配方法\n",
    "# img1中的每一个特征点都和img2中的每一个特征点之间计算描述子的向量距离(l1,l2,汉明距离....any_distance_function)\n",
    "# 然后对img1中的每个描述子返回在img2中与其最小距离的那个\n",
    "\n",
    "#特征匹配类\n",
    "# BFMatcher(normType,crossCheck)\n",
    "    # normType计算距离的方式    NORM_L1(sift surf),\n",
    "        #                       NORM_L2(sift surf),\n",
    "        #                       HAMMING(orb使用)  \n",
    "    # crossCheck 是否进行交叉匹配,默认False\n",
    "    \n",
    "# 创建 特征匹配类 实例对象后\n",
    "# 使用 match()方法进行匹配\n",
    "# 该方法返回 DMatch对象\n",
    "# DMatch对象.distance --描述符之间的距离\n",
    "#  .trainIdx -目标图像描述符索引\n",
    "#  .queryIdx -查询描述符索引\n",
    "#  .imgIdx  -目标图像索引\n",
    "\n",
    "# drawMatchs()绘制匹配特征点"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b2b4258e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "181\n",
      "181\n",
      "1462\n"
     ]
    }
   ],
   "source": [
    "img1 = cv2.imread('../data/linna.jpg')\n",
    "img1 = cv2.resize(img1,(150,150))\n",
    "gray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "img2 = cv2.imread('../data/linna.jpg')\n",
    "gray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# 进行检测\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1,des1 = surf.detectAndCompute(gray1,None)\n",
    "kp2,des2 = surf.detectAndCompute(gray2,None)\n",
    "\n",
    "# 暴力匹配\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1,False)\n",
    "\n",
    "# match(queryDescriptors, trainDescriptors[, mask]) -> matches\n",
    "matches = bf.match(des1,des2)\n",
    "\n",
    "print(type(matches))\n",
    "print(len(matches))\n",
    "print(len(des1))\n",
    "print(len(des2))\n",
    "# print(matches[0].distance,matches[0].imgIdx,matches[0].queryIdx,matches[0].trainIdx)\n",
    "outImg =cv2.drawMatches(img1,kp1,img2,kp2,matches,None)\n",
    "cv2.imshow('img',outImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2a484a9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "181\n",
      "181\n",
      "1462\n"
     ]
    }
   ],
   "source": [
    "# bf对象的 knnmatch 方法\n",
    "matches = bf.knnMatch(des1,des2,k = 2) # 每个描述子会返回k个匹配到的描述子\n",
    "print(type(matches))\n",
    "print(len(matches))\n",
    "print(len(des1))\n",
    "print(len(des2))\n",
    "outImg =cv2.drawMatchesKnn(img1,kp1,img2,kp2,matches,None)\n",
    "cv2.imshow('img',outImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6efdaa3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FLANN特征匹配 快速最近邻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a56303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 略"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9fee262",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 筛选部分配对的特征进行绘图\n",
    "\n",
    "# 找一个特征点少点的图来试验\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1edc3a",
   "metadata": {},
   "source": [
    "![img](../data/R-C.jpg)\n",
    "![img](../data/R-C-2.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "362fac91",
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = cv2.imread('../data/R-C.jpg')\n",
    "gray1 = cv2.cvtColor(img1,cv2.COLOR_BGR2GRAY)\n",
    "img2 = cv2.imread('../data/R-C-2.png')\n",
    "gray2 = cv2.cvtColor(img2,cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "sift = cv2.xfeatures2d.SIFT_create()\n",
    "kp1,des1 = sift.detectAndCompute(gray1,None)\n",
    "kp2,des2 = sift.detectAndCompute(gray2,None)\n",
    "\n",
    "out1 = cv2.drawKeypoints(img1,kp1,None)\n",
    "out2 = cv2.drawKeypoints(img2,kp2,None)\n",
    "\n",
    "# cv2.imshow('img',out2)\n",
    "# cv2.waitKey(0)\n",
    "# cv2.destroyAllWindows()\n",
    "\n",
    "bf = cv2.BFMatcher(cv2.NORM_L1,False)\n",
    "matches = bf.match(des2,des1)\n",
    "\n",
    "outImg =cv2.drawMatches(img2,kp2,img1,kp1,matches,None)\n",
    "cv2.imshow('img',outImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f0e3c4d",
   "metadata": {},
   "source": [
    "![image.png](001.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "2302cde9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "711.6835443037975\n"
     ]
    }
   ],
   "source": [
    "# 直接所有的配对项进行匹配错误的匹配较多\n",
    "# 选择比平均距离小的\n",
    "distance_list = [m.distance for m in matches]\n",
    "mean_distance = sum(distance_list)/len(distance_list)\n",
    "print(mean_distance)\n",
    "good_matches = [m for m in matches if m.distance<mean_distance]\n",
    "\n",
    "outImg =cv2.drawMatches(img2,kp2,img1,kp1,good_matches,None)\n",
    "cv2.imshow('img',outImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a480d65",
   "metadata": {},
   "source": [
    "少了一些错误,但是还不够完善\n",
    "![image-2.png](002.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "71ec8392",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 选择匹配距离前30%的\n",
    "distance_list = [m.distance for m in matches]\n",
    "idx = np.argsort(np.array(distance_list))\n",
    "good_idx = idx[0:int(0.3*len(distance_list))]\n",
    "# print(good_idx)\n",
    "good_matches = []\n",
    "for i in good_idx:\n",
    "    good_matches.append(matches[i])\n",
    "\n",
    "outImg =cv2.drawMatches(img2,kp2,img1,kp1,good_matches,None)\n",
    "cv2.imshow('img',outImg)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ac91a88",
   "metadata": {},
   "source": [
    "![image.png](003.png)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "opencv3_4_1_14",
   "language": "python",
   "name": "opencv3_4_1_14"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}